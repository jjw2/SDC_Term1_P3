{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images in Train1 :  4515\n",
      "Number of images in Train1 after fitering :  2598\n",
      "Total number of images in Train4 :  3747\n",
      "Number of images in Train4 after fitering :  3321\n",
      "Total number of images in Train6 :  4218\n",
      "Number of images in Train6 after fitering :  3537\n",
      "Total number of images in Train7 :  4110\n",
      "Number of images in Train7 after fitering :  3957\n",
      "Total number of images in Train8 :  12300\n",
      "Number of images in Train8 after fitering :  11181\n",
      "Total number of images in Train9 :  14712\n",
      "Number of images in Train9 after fitering :  13356\n",
      "Total number of images in Train11 :  4869\n",
      "Number of images in Train11 after fitering :  3765\n",
      "Total number of images in Train12 :  3234\n",
      "Number of images in Train12 after fitering :  2721\n",
      "Final number of images:  44436\n",
      "NOTE: This does not include any image flipping, which may occur later!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import random\n",
    "%matplotlib inline\n",
    "\n",
    "images = []\n",
    "measurements = []\n",
    "\n",
    "# Select which datasets to use for training\n",
    "# Thought about making this automatic, but wanted ability to select individual datasets\n",
    "#datasets = ['Train1', 'Train4', 'Train6', 'Train7']\n",
    "datasets = ['Train1', 'Train4', 'Train6', 'Train7', 'Train8', 'Train9', 'Train11', 'Train12']\n",
    "\n",
    "\n",
    "samples = []\n",
    "steer_correct = [0, 0.20, -0.20]\n",
    "\n",
    "steer_angle_thresh = 0.04\n",
    "steer_keep_pct = .33 # percentage of steering angles withn +/- steering threshold to keep\n",
    "\n",
    "# Loop thorugh selected datasets\n",
    "\n",
    "# Note: makes sense to do preprocessing here so batch size is properly attributed in the generator below\n",
    "\n",
    "for dataset in datasets:\n",
    "    tot_counter = 0;\n",
    "    dataset_counter = 0;\n",
    "    with open('data/' + dataset + '_log.csv') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        \n",
    "        for line in reader:\n",
    "            tot_counter = tot_counter + 1\n",
    "            # Filter out steering angles\n",
    "            this_steer = float(line[3])\n",
    "            \n",
    "            if (((this_steer <= -steer_angle_thresh) | (this_steer >= steer_angle_thresh))  | \n",
    "                ((this_steer >= -steer_angle_thresh) & (this_steer <= steer_angle_thresh) & (random() < steer_keep_pct))):\n",
    "                \n",
    "                # create a new line for center, left, right\n",
    "                for i in range(3): # center, left, right\n",
    "                    \n",
    "                    sourcepath = line[i]\n",
    "                    \n",
    "                    if(\"/\" in sourcepath):\n",
    "                        filename = sourcepath.split('/')[-1]\n",
    "                    else:\n",
    "                        filename = sourcepath.split('\\\\')[-1]\n",
    "\n",
    "                    newpath = 'data/' + dataset + '/' + filename\n",
    "\n",
    "                    newline = [newpath, this_steer+steer_correct[i]]            \n",
    "                    samples.append(newline)\n",
    "                    dataset_counter = dataset_counter + 1 \n",
    "            \n",
    "    \n",
    "    print(\"Total number of images in\", dataset, \": \" , tot_counter*3)\n",
    "    print(\"Number of images in\", dataset, \"after fitering : \", dataset_counter)\n",
    "\n",
    "print(\"Final number of images: \", len(samples))\n",
    "\n",
    "print(\"NOTE: This does not include any image flipping, which may occur later!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  14.,   18.,   16.,  148.,  268.,  330.,  231.,  838.,  750.,\n",
       "        1031., 1377., 1392., 1322., 1695., 2693., 1676., 2085., 1800.,\n",
       "        2753., 1550., 1898., 1557., 2284., 1826., 1851., 1168., 1324.,\n",
       "        1622.,  896., 1136., 1081., 1063.,  830.,  823.,  549.,  510.,\n",
       "         392.,  359.,  228.,  207.,  281.]),\n",
       " array([-1.        , -0.95121951, -0.90243902, -0.85365854, -0.80487805,\n",
       "        -0.75609756, -0.70731707, -0.65853659, -0.6097561 , -0.56097561,\n",
       "        -0.51219512, -0.46341463, -0.41463415, -0.36585366, -0.31707317,\n",
       "        -0.26829268, -0.2195122 , -0.17073171, -0.12195122, -0.07317073,\n",
       "        -0.02439024,  0.02439024,  0.07317073,  0.12195122,  0.17073171,\n",
       "         0.2195122 ,  0.26829268,  0.31707317,  0.36585366,  0.41463415,\n",
       "         0.46341463,  0.51219512,  0.56097561,  0.6097561 ,  0.65853659,\n",
       "         0.70731707,  0.75609756,  0.80487805,  0.85365854,  0.90243902,\n",
       "         0.95121951,  1.        ]),\n",
       " <a list of 41 Patch objects>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x4badac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "angles = []\n",
    "for sample in samples:\n",
    "    angles.append(sample[1])\n",
    "\n",
    "plt.hist(angles, bins=41, range=(-1.0, 1.0))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "\n",
    "# Split training and validation sets\n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2)            \n",
    "\n",
    "\n",
    "def generator(samples, batch_size = 64):\n",
    "    # Center, Left, Right\n",
    "    steer_correct = [0, 0.20, -0.20]\n",
    "    num_samples = len(samples)\n",
    "    \n",
    "    while 1:\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            \n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "            images = []\n",
    "            angles = []\n",
    "            for batch_sample in batch_samples:\n",
    "                    \n",
    "                path = batch_sample[0]\n",
    "                angle = batch_sample[1]\n",
    "\n",
    "                image = cv2.imread(path)\n",
    "                #plt.imshow(image)\n",
    "                \n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2YUV) # Suggested by nvidia\n",
    "                images.append(image)\n",
    "                images.append(cv2.flip(image,1)) #Flip image\n",
    "\n",
    "                angles.append(float(angle))\n",
    "                angles.append(float(-angle))\n",
    "\n",
    "            \n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "            yield sklearn.utils.shuffle(X_train, y_train)\n",
    "        \n",
    "train_generator = generator(train_samples, batch_size=128)\n",
    "validation_generator = generator(validation_samples, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "47288/71096 [==================>...........] - ETA: 91s - loss: 0.0529"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-0bb8b86ce785>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m \u001b[0mnvidia1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-0bb8b86ce785>\u001b[0m in \u001b[0;36mnvidia1\u001b[1;34m()\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'mse'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'adam'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \tmodel.fit_generator(train_generator, samples_per_epoch = len(train_samples)*2,\n\u001b[1;32m---> 77\u001b[1;33m                         validation_data=validation_generator, nb_val_samples=len(validation_samples)*2, nb_epoch=3)\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\carnd-term1\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    933\u001b[0m                                         \u001b[0mnb_worker\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnb_worker\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m                                         \u001b[0mpickle_safe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpickle_safe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 935\u001b[1;33m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m    936\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m     def evaluate_generator(self, generator, val_samples,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\carnd-term1\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch)\u001b[0m\n\u001b[0;32m   1551\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   1552\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1553\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   1554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1555\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\carnd-term1\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1314\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1316\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1317\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\carnd-term1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   1898\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1899\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m-> 1900\u001b[1;33m                               feed_dict=feed_dict)\n\u001b[0m\u001b[0;32m   1901\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1902\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\carnd-term1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\carnd-term1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\carnd-term1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\carnd-term1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\carnd-term1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\carnd-term1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Set Up NNs ##\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Cropping2D, Convolution2D, MaxPooling2D, Dropout\n",
    "\n",
    "\n",
    "dropout = [0.0, 0.3, 0.3, 0.5]\n",
    "\n",
    "\n",
    "def LeNet1():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Cropping2D(cropping=((50,20), (0,0)), input_shape=(160, 320, 3)))\n",
    "\tmodel.add(Lambda(lambda x:(x/255.0)-0.5))\n",
    "\tmodel.add(Convolution2D(10, 5, 5, activation='relu'))\n",
    "\tmodel.add(MaxPooling2D())\n",
    "\tmodel.add(Convolution2D(20, 5, 5, activation='relu'))\n",
    "\tmodel.add(MaxPooling2D())\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(120))\n",
    "\tmodel.add(Dense(84))\n",
    "\tmodel.add(Dense(1))\n",
    "\n",
    "\tmodel.compile(loss = 'mse', optimizer = 'adam')\n",
    "\tmodel.fit(X_train, y_train, validation_split=0.2, shuffle=True, nb_epoch=7, batch_size=128)\n",
    "\n",
    "\tmodel.save('model.h5')\n",
    "\n",
    "def nvidia():\n",
    "\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Cropping2D(cropping=((50,20), (0,0)), input_shape=(160, 320, 3)))\n",
    "\tmodel.add(Lambda(lambda x:(x/255.0)-0.5))\n",
    "\tmodel.add(Convolution2D(24, 5, 5, subsample=(2,2), activation='relu'))#78x158\n",
    "\tmodel.add(Dropout(dropout[1]))\n",
    "\tmodel.add(Convolution2D(36, 5, 5, subsample=(2,2), activation='relu'))#37x77\n",
    "\tmodel.add(Dropout(dropout[1]))\n",
    "\tmodel.add(Convolution2D(48, 5, 5, subsample=(2,2), activation='relu'))#16x36\n",
    "\tmodel.add(Dropout(dropout[1]))\n",
    "\tmodel.add(Convolution2D(64, 5, 5, subsample=(2,2), activation='relu'))#2x17\n",
    "\tmodel.add(Dropout(dropout[1]))\n",
    "\t#model.add(Convolution2D(64, 5, 5, subsample=(2,1), activation='relu'))#1x12\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(1000))\n",
    "\tmodel.add(Dropout(dropout[3]))\n",
    "\tmodel.add(Dense(100))\n",
    "\tmodel.add(Dense(50))\n",
    "\tmodel.add(Dense(1))\n",
    "\n",
    "\tmodel.compile(loss = 'mse', optimizer = 'adam')\n",
    "\tmodel.fit(X_train, y_train, validation_split=0.2, shuffle=True, nb_epoch=3, batch_size=512)\n",
    "\n",
    "\tmodel.save('model.h5')\n",
    "\n",
    "def nvidia1():\n",
    "\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Cropping2D(cropping=((74,20), (30,30)), input_shape=(160, 320, 3))) # 66, 260\n",
    "\tmodel.add(Lambda(lambda x:(x/255.0)-0.5))\n",
    "\tmodel.add(Convolution2D(24, 5, 5, subsample=(2,2), activation='relu'))#31x98\n",
    "\tmodel.add(Dropout(dropout[1]))\n",
    "\tmodel.add(Convolution2D(36, 5, 5, subsample=(2,2), activation='relu'))#14X47\n",
    "\tmodel.add(Dropout(dropout[1]))\n",
    "\tmodel.add(Convolution2D(48, 5, 5, subsample=(2,2), activation='relu'))#5x22\n",
    "\tmodel.add(Dropout(dropout[1]))\n",
    "\tmodel.add(Convolution2D(64, 3, 3, subsample=(1,1), activation='relu'))#3x20\n",
    "\tmodel.add(Dropout(dropout[1]))\n",
    "\tmodel.add(Convolution2D(64, 3, 3, subsample=(1,1), activation='relu'))#1x18\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(1000))\n",
    "\tmodel.add(Dropout(dropout[3]))\n",
    "\tmodel.add(Dense(100))\n",
    "\tmodel.add(Dropout(dropout[3]))\n",
    "\tmodel.add(Dense(50))\n",
    "\tmodel.add(Dense(1))\n",
    "\n",
    "\tmodel.compile(loss = 'mse', optimizer = 'adam')\n",
    "\tmodel.fit_generator(train_generator, samples_per_epoch = len(train_samples)*2,\n",
    "                        validation_data=validation_generator, nb_val_samples=len(validation_samples)*2, nb_epoch=3)\n",
    "\n",
    "\tmodel.save('model.h5')\n",
    "\n",
    "def nvidia2():\n",
    "\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Cropping2D(cropping=((74,20), (40,40)), input_shape=(160, 320, 3))) # 66, 200\n",
    "\tmodel.add(Lambda(lambda x:(x/255.0)-0.5))\n",
    "\tmodel.add(Convolution2D(24, 5, 5, subsample=(2,2), activation='relu'))#31x98\n",
    "\tmodel.add(Dropout(dropout[1]))\n",
    "\tmodel.add(Convolution2D(36, 5, 5, subsample=(2,2), activation='relu'))#14X47\n",
    "\tmodel.add(Dropout(dropout[1]))\n",
    "\tmodel.add(Convolution2D(48, 5, 5, subsample=(2,2), activation='relu'))#5x22\n",
    "\tmodel.add(Dropout(dropout[1]))\n",
    "\tmodel.add(Convolution2D(64, 3, 3, subsample=(1,1), activation='relu'))#3x20\n",
    "\tmodel.add(Dropout(dropout[1]))\n",
    "\tmodel.add(Convolution2D(64, 3, 3, subsample=(1,1), activation='relu'))#1x18\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(1000))\n",
    "\tmodel.add(Dropout(dropout[3]))\n",
    "\tmodel.add(Dense(100))\n",
    "\tmodel.add(Dropout(dropout[3]))\n",
    "\tmodel.add(Dense(50))\n",
    "\tmodel.add(Dense(1))\n",
    "\n",
    "\tmodel.compile(loss = 'mse', optimizer = 'adam')\n",
    "\tmodel.fit(X_train, y_train, validation_split=0.2, shuffle=True, nb_epoch=3, batch_size=256)\n",
    "\n",
    "\tmodel.save('model.h5')\n",
    "\n",
    "\n",
    "nvidia1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
