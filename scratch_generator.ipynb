{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images in Train1 :  4515\n",
      "Number of images in Train1 after fitering :  2613\n",
      "Total number of images in Train4 :  3747\n",
      "Number of images in Train4 after fitering :  3333\n",
      "Total number of images in Train6 :  4218\n",
      "Number of images in Train6 after fitering :  3573\n",
      "Total number of images in Train7 :  4110\n",
      "Number of images in Train7 after fitering :  3939\n",
      "Final number of images:  13458\n",
      "NOTE: This does not include any image flipping, which may occur later!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import random\n",
    "%matplotlib inline\n",
    "\n",
    "images = []\n",
    "measurements = []\n",
    "\n",
    "# Select which datasets to use for training\n",
    "# Thought about making this automatic, but wanted ability to select individual datasets\n",
    "datasets = ['Train1', 'Train4', 'Train6', 'Train7']#, 'Train2', 'Train4', 'Train5']\n",
    "\n",
    "\n",
    "samples = []\n",
    "steer_correct = [0, 0.20, -0.20]\n",
    "\n",
    "steer_angle_thresh = 0.04\n",
    "steer_keep_pct = .33 # percentage of steering angles withn +/- steering threshold to keep\n",
    "\n",
    "# Loop thorugh selected datasets\n",
    "\n",
    "# Note: makes sense to do preprocessing here so batch size is properly attributed in the generator below\n",
    "\n",
    "for dataset in datasets:\n",
    "    tot_counter = 0;\n",
    "    dataset_counter = 0;\n",
    "    with open('data/' + dataset + '_log.csv') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        \n",
    "        for line in reader:\n",
    "            tot_counter = tot_counter + 1\n",
    "            # Filter out steering angles\n",
    "            this_steer = float(line[3])\n",
    "            \n",
    "            if (((this_steer <= -steer_angle_thresh) | (this_steer >= steer_angle_thresh))  | \n",
    "                ((this_steer >= -steer_angle_thresh) & (this_steer <= steer_angle_thresh) & (random() < steer_keep_pct))):\n",
    "                \n",
    "                # create a new line for center, left, right\n",
    "                for i in range(3): # center, left, right\n",
    "                    \n",
    "                    sourcepath = line[i]\n",
    "                    \n",
    "                    if(\"/\" in sourcepath):\n",
    "                        filename = sourcepath.split('/')[-1]\n",
    "                    else:\n",
    "                        filename = sourcepath.split('\\\\')[-1]\n",
    "\n",
    "                    newpath = 'data/' + dataset + '/' + filename\n",
    "\n",
    "                    newline = [newpath, this_steer+steer_correct[i]]            \n",
    "                    samples.append(newline)\n",
    "                    dataset_counter = dataset_counter + 1 \n",
    "            \n",
    "    \n",
    "    print(\"Total number of images in\", dataset, \": \" , tot_counter*3)\n",
    "    print(\"Number of images in\", dataset, \"after fitering : \", dataset_counter)\n",
    "\n",
    "print(\"Final number of images: \", len(samples))\n",
    "\n",
    "print(\"NOTE: This does not include any image flipping, which may occur later!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   5.,    3.,   12.,   22.,   80.,   79.,   66.,  294.,  186.,\n",
       "         141.,  299.,  409.,  342.,  306., 1009.,  582.,  702.,  380.,\n",
       "        1130.,  451.,  721.,  469.,  992.,  594.,  703.,  397.,  426.,\n",
       "         452.,  246.,  350.,  316.,  315.,  160.,  227.,  164.,  151.,\n",
       "          30.,  100.,   75.,   45.,    3.]),\n",
       " array([-1.        , -0.95121951, -0.90243902, -0.85365854, -0.80487805,\n",
       "        -0.75609756, -0.70731707, -0.65853659, -0.6097561 , -0.56097561,\n",
       "        -0.51219512, -0.46341463, -0.41463415, -0.36585366, -0.31707317,\n",
       "        -0.26829268, -0.2195122 , -0.17073171, -0.12195122, -0.07317073,\n",
       "        -0.02439024,  0.02439024,  0.07317073,  0.12195122,  0.17073171,\n",
       "         0.2195122 ,  0.26829268,  0.31707317,  0.36585366,  0.41463415,\n",
       "         0.46341463,  0.51219512,  0.56097561,  0.6097561 ,  0.65853659,\n",
       "         0.70731707,  0.75609756,  0.80487805,  0.85365854,  0.90243902,\n",
       "         0.95121951,  1.        ]),\n",
       " <a list of 41 Patch objects>)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b40add8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "angles = []\n",
    "for sample in samples:\n",
    "    angles.append(sample[1])\n",
    "\n",
    "plt.hist(angles, bins=41, range=(-1.0, 1.0))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "\n",
    "# Split training and validation sets\n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2)            \n",
    "\n",
    "\n",
    "def generator(samples, batch_size = 64):\n",
    "    # Center, Left, Right\n",
    "    steer_correct = [0, 0.20, -0.20]\n",
    "    num_samples = len(samples)\n",
    "    \n",
    "    while 1:\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            \n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "            images = []\n",
    "            angles = []\n",
    "            for batch_sample in batch_samples:\n",
    "                    \n",
    "                path = batch_sample[0]\n",
    "                angle = batch_sample[1]\n",
    "\n",
    "                image = cv2.imread(path)\n",
    "                #plt.imshow(image)\n",
    "                \n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2YUV) # Suggested by nvidia\n",
    "                images.append(image)\n",
    "                images.append(cv2.flip(image,1)) #Flip image\n",
    "\n",
    "                angles.append(float(angle))\n",
    "                angles.append(float(-angle))\n",
    "\n",
    "            \n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "            yield sklearn.utils.shuffle(X_train, y_train)\n",
    "        \n",
    "train_generator = generator(train_samples, batch_size=32)\n",
    "validation_generator = generator(validation_samples, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "21532/21532 [==============================] - 93s - loss: 0.0439 - val_loss: 0.0338\n",
      "Epoch 2/3\n",
      "21532/21532 [==============================] - 92s - loss: 0.0294 - val_loss: 0.0262\n",
      "Epoch 3/3\n",
      "21532/21532 [==============================] - 92s - loss: 0.0261 - val_loss: 0.0243\n"
     ]
    }
   ],
   "source": [
    "## Set Up NNs ##\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Cropping2D, Convolution2D, MaxPooling2D, Dropout\n",
    "\n",
    "\n",
    "dropout = [0.0, 0.3, 0.3, 0.5]\n",
    "\n",
    "\n",
    "def LeNet1():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Cropping2D(cropping=((50,20), (0,0)), input_shape=(160, 320, 3)))\n",
    "\tmodel.add(Lambda(lambda x:(x/255.0)-0.5))\n",
    "\tmodel.add(Convolution2D(10, 5, 5, activation='relu'))\n",
    "\tmodel.add(MaxPooling2D())\n",
    "\tmodel.add(Convolution2D(20, 5, 5, activation='relu'))\n",
    "\tmodel.add(MaxPooling2D())\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(120))\n",
    "\tmodel.add(Dense(84))\n",
    "\tmodel.add(Dense(1))\n",
    "\n",
    "\tmodel.compile(loss = 'mse', optimizer = 'adam')\n",
    "\tmodel.fit(X_train, y_train, validation_split=0.2, shuffle=True, nb_epoch=7, batch_size=128)\n",
    "\n",
    "\tmodel.save('model.h5')\n",
    "\n",
    "def nvidia():\n",
    "\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Cropping2D(cropping=((50,20), (0,0)), input_shape=(160, 320, 3)))\n",
    "\tmodel.add(Lambda(lambda x:(x/255.0)-0.5))\n",
    "\tmodel.add(Convolution2D(24, 5, 5, subsample=(2,2), activation='relu'))#78x158\n",
    "\tmodel.add(Dropout(dropout[1]))\n",
    "\tmodel.add(Convolution2D(36, 5, 5, subsample=(2,2), activation='relu'))#37x77\n",
    "\tmodel.add(Dropout(dropout[1]))\n",
    "\tmodel.add(Convolution2D(48, 5, 5, subsample=(2,2), activation='relu'))#16x36\n",
    "\tmodel.add(Dropout(dropout[1]))\n",
    "\tmodel.add(Convolution2D(64, 5, 5, subsample=(2,2), activation='relu'))#2x17\n",
    "\tmodel.add(Dropout(dropout[1]))\n",
    "\t#model.add(Convolution2D(64, 5, 5, subsample=(2,1), activation='relu'))#1x12\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(1000))\n",
    "\tmodel.add(Dropout(dropout[3]))\n",
    "\tmodel.add(Dense(100))\n",
    "\tmodel.add(Dense(50))\n",
    "\tmodel.add(Dense(1))\n",
    "\n",
    "\tmodel.compile(loss = 'mse', optimizer = 'adam')\n",
    "\tmodel.fit(X_train, y_train, validation_split=0.2, shuffle=True, nb_epoch=3, batch_size=256)\n",
    "\n",
    "\tmodel.save('model.h5')\n",
    "\n",
    "def nvidia1():\n",
    "\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Cropping2D(cropping=((74,20), (30,30)), input_shape=(160, 320, 3))) # 66, 260\n",
    "\tmodel.add(Lambda(lambda x:(x/255.0)-0.5))\n",
    "\tmodel.add(Convolution2D(24, 5, 5, subsample=(2,2), activation='relu'))#31x98\n",
    "\tmodel.add(Dropout(dropout[1]))\n",
    "\tmodel.add(Convolution2D(36, 5, 5, subsample=(2,2), activation='relu'))#14X47\n",
    "\tmodel.add(Dropout(dropout[1]))\n",
    "\tmodel.add(Convolution2D(48, 5, 5, subsample=(2,2), activation='relu'))#5x22\n",
    "\tmodel.add(Dropout(dropout[1]))\n",
    "\tmodel.add(Convolution2D(64, 3, 3, subsample=(1,1), activation='relu'))#3x20\n",
    "\tmodel.add(Dropout(dropout[1]))\n",
    "\tmodel.add(Convolution2D(64, 3, 3, subsample=(1,1), activation='relu'))#1x18\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(1000))\n",
    "\tmodel.add(Dropout(dropout[3]))\n",
    "\tmodel.add(Dense(100))\n",
    "\tmodel.add(Dropout(dropout[3]))\n",
    "\tmodel.add(Dense(50))\n",
    "\tmodel.add(Dense(1))\n",
    "\n",
    "\tmodel.compile(loss = 'mse', optimizer = 'adam')\n",
    "\tmodel.fit_generator(train_generator, samples_per_epoch = len(train_samples)*2,\n",
    "                        validation_data=validation_generator, nb_val_samples=len(validation_samples)*2, nb_epoch=3)\n",
    "\n",
    "\tmodel.save('model.h5')\n",
    "\n",
    "def nvidia2():\n",
    "\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Cropping2D(cropping=((74,20), (40,40)), input_shape=(160, 320, 3))) # 66, 200\n",
    "\tmodel.add(Lambda(lambda x:(x/255.0)-0.5))\n",
    "\tmodel.add(Convolution2D(24, 5, 5, subsample=(2,2), activation='relu'))#31x98\n",
    "\tmodel.add(Dropout(dropout[1]))\n",
    "\tmodel.add(Convolution2D(36, 5, 5, subsample=(2,2), activation='relu'))#14X47\n",
    "\tmodel.add(Dropout(dropout[1]))\n",
    "\tmodel.add(Convolution2D(48, 5, 5, subsample=(2,2), activation='relu'))#5x22\n",
    "\tmodel.add(Dropout(dropout[1]))\n",
    "\tmodel.add(Convolution2D(64, 3, 3, subsample=(1,1), activation='relu'))#3x20\n",
    "\tmodel.add(Dropout(dropout[1]))\n",
    "\tmodel.add(Convolution2D(64, 3, 3, subsample=(1,1), activation='relu'))#1x18\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(1000))\n",
    "\tmodel.add(Dropout(dropout[3]))\n",
    "\tmodel.add(Dense(100))\n",
    "\tmodel.add(Dropout(dropout[3]))\n",
    "\tmodel.add(Dense(50))\n",
    "\tmodel.add(Dense(1))\n",
    "\n",
    "\tmodel.compile(loss = 'mse', optimizer = 'adam')\n",
    "\tmodel.fit(X_train, y_train, validation_split=0.2, shuffle=True, nb_epoch=3, batch_size=128)\n",
    "\n",
    "\tmodel.save('model.h5')\n",
    "\n",
    "\n",
    "nvidia1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
